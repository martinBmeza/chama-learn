{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6e8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 15:35:35.731884: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import numpy \n",
    "import tqdm \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044615f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El largo del dataset es de 1933003 caracteres y contiene 37 caracteres unicos\n"
     ]
    }
   ],
   "source": [
    "path_to_file = '../data/folclore-web/clean_dataset.txt'\n",
    "#path_to_file = '../data/chamame-web/clean_dataset.txt'\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "vocab = sorted(set(text))\n",
    "print('El largo del dataset es de {} caracteres y contiene {} caracteres unicos'.format(len(text), len(set(vocab))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633dbc4",
   "metadata": {},
   "source": [
    "# Procesamiento del texto\n",
    "\n",
    "\n",
    "Primero se convierte el texto en tokens (separo en caracteres), despues uso la capa StringLookup para convertir cada caracter en un numero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937ba4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 15:35:37.701570: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-18 15:35:37.746541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:37.746719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.7715GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2021-11-18 15:35:37.746735: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-18 15:35:37.749398: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-18 15:35:37.749425: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-11-18 15:35:37.750873: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-18 15:35:37.751076: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-18 15:35:37.751462: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-11-18 15:35:37.752120: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-11-18 15:35:37.752221: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-11-18 15:35:37.752310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:37.752581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:37.752763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-11-18 15:35:37.753314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-18 15:35:37.753980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:37.754133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.7715GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2021-11-18 15:35:37.754198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:37.754367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:37.754501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-11-18 15:35:37.754524: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-18 15:35:38.146528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-18 15:35:38.146549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-11-18 15:35:38.146554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-11-18 15:35:38.146679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:38.146866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:38.147021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-18 15:35:38.147157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 116 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2021-11-18 15:35:38.192066: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 116.50M (122159104 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "chars = tf.strings.unicode_split(text, input_encoding='UTF-8') # divido en caracteres\n",
    "# armo una capa para ir de ids a chars, y otra para ir de chars a ids\n",
    "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "chars_from_ids = preprocessing.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4356bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "seq_length = 200\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea01c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probando resultados con baches\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe4711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 15:35:39.451261: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-18 15:35:39.470265: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3199980000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64, 200), dtype=int64, numpy=\n",
      "array([[32, 18, 26, ..., 26, 24, 26],\n",
      "       [ 2,  1, 28, ..., 25, 15, 26],\n",
      "       [ 1, 31, 29, ..., 30, 12, 21],\n",
      "       ...,\n",
      "       [20, 26,  2, ...,  2, 27, 16],\n",
      "       [23, 12,  2, ..., 18, 26,  1],\n",
      "       [26,  2, 28, ..., 36,  2, 32]])>, <tf.Tensor: shape=(64, 200), dtype=int64, numpy=\n",
      "array([[18, 26,  2, ..., 24, 26,  2],\n",
      "       [ 1, 28, 32, ..., 15, 26,  2],\n",
      "       [31, 29, 16, ..., 12, 21, 16],\n",
      "       ...,\n",
      "       [26,  2,  2, ..., 27, 16, 14],\n",
      "       [12,  2, 30, ..., 26,  1,  1],\n",
      "       [ 2, 28, 32, ...,  2, 32, 25]])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d1791",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef1371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  380       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  3182592   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  38950     \n",
      "=================================================================\n",
      "Total params: 3,221,922\n",
      "Trainable params: 3,221,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "50# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 10\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "model = MyModel(vocab_size=len(ids_from_chars.get_vocabulary()), embedding_dim=embedding_dim, rnn_units=rnn_units)\n",
    "model.build((64, 200))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93fe2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 15:36:40.370848: W tensorflow/core/common_runtime/bfc_allocator.cc:456] Allocator (GPU_0_bfc) ran out of memory trying to allocate 12.14MiB (rounded to 12730368)requested by op concat_0\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2021-11-18 15:36:40.370910: I tensorflow/core/common_runtime/bfc_allocator.cc:991] BFCAllocator dump for GPU_0_bfc\n",
      "2021-11-18 15:36:40.370937: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (256): \tTotal Chunks: 46, Chunks in use: 46. 11.5KiB allocated for chunks. 11.5KiB in use in bin. 1.1KiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.370954: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.370971: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.370986: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371003: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (4096): \tTotal Chunks: 6, Chunks in use: 6. 24.0KiB allocated for chunks. 24.0KiB in use in bin. 24.0KiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371018: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371036: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (16384): \tTotal Chunks: 5, Chunks in use: 5. 120.0KiB allocated for chunks. 120.0KiB in use in bin. 120.0KiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371055: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (32768): \tTotal Chunks: 6, Chunks in use: 6. 280.8KiB allocated for chunks. 280.8KiB in use in bin. 244.0KiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371073: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (65536): \tTotal Chunks: 5, Chunks in use: 5. 580.2KiB allocated for chunks. 580.2KiB in use in bin. 580.0KiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371090: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (131072): \tTotal Chunks: 8, Chunks in use: 8. 1.28MiB allocated for chunks. 1.28MiB in use in bin. 1.12MiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371106: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (262144): \tTotal Chunks: 4, Chunks in use: 4. 1.48MiB allocated for chunks. 1.48MiB in use in bin. 1.48MiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371120: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371134: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371149: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 0. 3.98MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371167: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 3. 13.56MiB allocated for chunks. 13.56MiB in use in bin. 12.00MiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371184: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (8388608): \tTotal Chunks: 5, Chunks in use: 5. 60.00MiB allocated for chunks. 60.00MiB in use in bin. 60.00MiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371202: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 23.55MiB allocated for chunks. 23.55MiB in use in bin. 12.00MiB client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371217: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371231: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371251: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371266: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2021-11-18 15:36:40.371282: I tensorflow/core/common_runtime/bfc_allocator.cc:1014] Bin for 12.14MiB was 8.00MiB, Chunk State: \n",
      "2021-11-18 15:36:40.371294: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] Next region of size 109943296\n",
      "2021-11-18 15:36:40.371316: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000000 of size 1280 by op ScratchBuffer action_count 5697193716543325967 step 0 next 1\n",
      "2021-11-18 15:36:40.371331: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000500 of size 256 by op AssignVariableOp action_count 5697193716543325992 step 0 next 4\n",
      "2021-11-18 15:36:40.371344: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000600 of size 256 by op Mul action_count 5697193716543326003 step 0 next 9\n",
      "2021-11-18 15:36:40.371356: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000700 of size 256 by op Add action_count 5697193716543326005 step 0 next 11\n",
      "2021-11-18 15:36:40.371368: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000800 of size 256 by op Fill action_count 5697193716543326024 step 0 next 6\n",
      "2021-11-18 15:36:40.371380: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000900 of size 256 by op Sub action_count 5697193716543326027 step 0 next 17\n",
      "2021-11-18 15:36:40.371391: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000a00 of size 256 by op Sub action_count 5697193716543326028 step 0 next 18\n",
      "2021-11-18 15:36:40.371403: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000b00 of size 256 by op Fill action_count 5697193716543326035 step 0 next 16\n",
      "2021-11-18 15:36:40.371414: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000c00 of size 256 by op Fill action_count 5697193716543326036 step 0 next 21\n",
      "2021-11-18 15:36:40.371426: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000d00 of size 256 by op Fill action_count 5697193716543326037 step 0 next 22\n",
      "2021-11-18 15:36:40.371437: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000e00 of size 256 by op AssignVariableOp action_count 5697193716543326038 step 0 next 23\n",
      "2021-11-18 15:36:40.371449: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0000f00 of size 256 by op Fill action_count 5697193716543326046 step 0 next 24\n",
      "2021-11-18 15:36:40.371461: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001000 of size 256 by op Equal action_count 5697193716543326040 step 0 next 25\n",
      "2021-11-18 15:36:40.371472: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001100 of size 256 by op AssignVariableOp action_count 5697193716543326047 step 0 next 26\n",
      "2021-11-18 15:36:40.371484: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001200 of size 256 by op AssignVariableOp action_count 5697193716543326048 step 0 next 27\n",
      "2021-11-18 15:36:40.371495: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001300 of size 256 by op AssignVariableOp action_count 5697193716543326049 step 0 next 28\n",
      "2021-11-18 15:36:40.371507: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001400 of size 256 by op AssignVariableOp action_count 5697193716543326050 step 0 next 29\n",
      "2021-11-18 15:36:40.371518: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001500 of size 256 by op Fill action_count 5697193716543326051 step 0 next 30\n",
      "2021-11-18 15:36:40.371533: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001600 of size 256 by op Fill action_count 5697193716543326056 step 0 next 34\n",
      "2021-11-18 15:36:40.371545: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001700 of size 256 by op Fill action_count 5697193716543326061 step 0 next 13\n",
      "2021-11-18 15:36:40.371557: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001800 of size 256 by op Mul action_count 5697193716543326018 step 0 next 15\n",
      "2021-11-18 15:36:40.371569: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0001900 of size 24576 by op Fill action_count 5697193716543326025 step 0 next 10\n",
      "2021-11-18 15:36:40.371581: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0007900 of size 24576 by op Fill action_count 5697193716543326054 step 0 next 32\n",
      "2021-11-18 15:36:40.371592: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c000d900 of size 24576 by op Fill action_count 5697193716543326059 step 0 next 35\n",
      "2021-11-18 15:36:40.371604: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0013900 of size 256 by op Adam/add_1/y action_count 5697193716543326062 step 0 next 37\n",
      "2021-11-18 15:36:40.371616: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0013a00 of size 256 by op Adam/Const_1 action_count 5697193716543326063 step 0 next 38\n",
      "2021-11-18 15:36:40.371628: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0013b00 of size 256 by op Sum_1 action_count 5697193716543326065 step 0 next 40\n",
      "2021-11-18 15:36:40.371641: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0013c00 of size 256 by op sparse_categorical_crossentropy/weighted_loss/num_elements/Cast action_count 5697193716543326066 step 0 next 41\n",
      "2021-11-18 15:36:40.371653: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0013d00 of size 256 by op Const action_count 5697193716543326067 step 0 next 42\n",
      "2021-11-18 15:36:40.371665: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0013e00 of size 256 by op Adam/Adam/Const action_count 5697193716543326068 step 0 next 43\n",
      "2021-11-18 15:36:40.371676: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0013f00 of size 256 by op Fill action_count 5697193716543326161 step 0 next 63\n",
      "2021-11-18 15:36:40.371688: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0014000 of size 256 by op Fill action_count 5697193716543326162 step 0 next 45\n",
      "2021-11-18 15:36:40.371700: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0014100 of size 256 by op CudnnRNN/input_c action_count 5697193716543326082 step 0 next 50\n",
      "2021-11-18 15:36:40.371712: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0014200 of size 41984 by op Fill action_count 5697193716543326153 step 0 next 2\n",
      "2021-11-18 15:36:40.371724: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c001e600 of size 256 by op Sub action_count 5697193716543325994 step 0 next 3\n",
      "2021-11-18 15:36:40.371736: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c001e700 of size 256 by op Sub action_count 5697193716543325995 step 0 next 5\n",
      "2021-11-18 15:36:40.371748: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c001e800 of size 123136 by op Fill action_count 5697193716543326052 step 0 next 7\n",
      "2021-11-18 15:36:40.371761: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c003c900 of size 122880 by op Add action_count 5697193716543325999 step 0 next 8\n",
      "2021-11-18 15:36:40.371775: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c005a900 of size 155648 "
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": " [_Derived_]RecvAsync is cancelled.\n\t [[{{node gradient_tape/my_model_1/embedding_1/embedding_lookup/Reshape/_18}}]] [Op:__inference_train_function_5068]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57914/3905488504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCancelledError\u001b[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node gradient_tape/my_model_1/embedding_1/embedding_lookup/Reshape/_18}}]] [Op:__inference_train_function_5068]\n\nFunction call stack:\ntrain_function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "by op Fill action_count 5697193716543326055 step 0 next 33\n",
      "2021-11-18 15:36:40.371787: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0080900 of size 155648 by op Fill action_count 5697193716543326057 step 0 next 20\n",
      "2021-11-18 15:36:40.371804: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c00a6900 of size 155648 by op Add action_count 5697193716543326032 step 0 next 19\n",
      "2021-11-18 15:36:40.371817: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c00cc900 of size 12582912 by op Fill action_count 5697193716543326053 step 0 next 31\n",
      "2021-11-18 15:36:40.371829: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c0ccc900 of size 24698880 by op Fill action_count 5697193716543326058 step 0 next 12\n",
      "2021-11-18 15:36:40.371842: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c245a900 of size 12582912 by op Mul action_count 5697193716543326019 step 0 next 14\n",
      "2021-11-18 15:36:40.371853: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c305a900 of size 155648 by op Fill action_count 5697193716543326060 step 0 next 36\n",
      "2021-11-18 15:36:40.371867: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c3080900 of size 51200 by op gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/ExpandDims action_count 5697193716543326064 step 0 next 39\n",
      "2021-11-18 15:36:40.371880: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c308d100 of size 24576 by op Fill action_count 5697193716543326175 step 0 next 59\n",
      "2021-11-18 15:36:40.371892: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c3093100 of size 221184 by op Fill action_count 5697193716543326176 step 0 next 44\n",
      "2021-11-18 15:36:40.371904: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c30c9100 of size 122880 by op Add action_count 5697193716543326131 step 0 next 47\n",
      "2021-11-18 15:36:40.371916: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c30e7100 of size 256 by op Fill action_count 5697193716543326163 step 0 next 46\n",
      "2021-11-18 15:36:40.371927: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c30e7200 of size 256 by op Fill action_count 5697193716543326164 step 0 next 54\n",
      "2021-11-18 15:36:40.371939: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c30e7300 of size 256 by op Fill action_count 5697193716543326165 step 0 next 64\n",
      "2021-11-18 15:36:40.371950: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c30e7400 of size 256 by op Fill action_count 5697193716543326172 step 0 next 61\n",
      "2021-11-18 15:36:40.371963: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c30e7500 of size 154624 by op Fill action_count 5697193716543326173 step 0 next 55\n",
      "2021-11-18 15:36:40.371975: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c310d100 of size 192512 by op Add action_count 5697193716543326158 step 0 next 48\n",
      "2021-11-18 15:36:40.371988: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c313c100 of size 262144 by op ExpandDims action_count 5697193716543326081 step 0 next 49\n",
      "2021-11-18 15:36:40.372000: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c317c100 of size 12582912 by op Mul action_count 5697193716543326148 step 0 next 60\n",
      "2021-11-18 15:36:40.372012: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c3d7c100 of size 12582912 by op Fill action_count 5697193716543326174 step 0 next 58\n",
      "2021-11-18 15:36:40.372023: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c497c100 of size 256 by op Fill action_count 5697193716543326177 step 0 next 57\n",
      "2021-11-18 15:36:40.372035: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c497c200 of size 122880 by op Fill action_count 5697193716543326178 step 0 next 56\n",
      "2021-11-18 15:36:40.372047: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c499a200 of size 12582912 by op Fill action_count 5697193716543326179 step 0 next 52\n",
      "2021-11-18 15:36:40.372059: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c559a200 of size 24576 by op Fill action_count 5697193716543326180 step 0 next 53\n",
      "2021-11-18 15:36:40.372072: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55a0200 of size 155648 by op Fill action_count 5697193716543326181 step 0 next 62\n",
      "2021-11-18 15:36:40.372085: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55c6200 of size 256 by op Fill action_count 5697193716543326182 step 0 next 51\n",
      "2021-11-18 15:36:40.372097: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55c6300 of size 256 by op Adam/add_1/y action_count 5697193716543326183 step 0 next 65\n",
      "2021-11-18 15:36:40.372139: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55c6400 of size 256 by op Adam/Const_1 action_count 5697193716543326184 step 0 next 66\n",
      "2021-11-18 15:36:40.372181: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55c6500 of size 51200 by op gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/ExpandDims action_count 5697193716543326185 step 0 next 67\n",
      "2021-11-18 15:36:40.372207: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55d2d00 of size 256 by op Sum_1 action_count 5697193716543326186 step 0 next 68\n",
      "2021-11-18 15:36:40.372231: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55d2e00 of size 256 by op sparse_categorical_crossentropy/weighted_loss/num_elements/Cast action_count 5697193716543326187 step 0 next 69\n",
      "2021-11-18 15:36:40.372255: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55d2f00 of size 256 by op Const action_count 5697193716543326188 step 0 next 70\n",
      "2021-11-18 15:36:40.372278: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55d3000 of size 256 by op Adam/Adam/Const action_count 5697193716543326189 step 0 next 71\n",
      "2021-11-18 15:36:40.372303: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55d3100 of size 256 by op Adam/Pow_2 action_count 5697193716543326193 step 17118782394153560157 next 72\n",
      "2021-11-18 15:36:40.372322: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55d3200 of size 256 by op Adam/Cast_5 action_count 5697193716543326191 step 17118782394153560157 next 73\n",
      "2021-11-18 15:36:40.372341: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55d3300 of size 102400 by op sparse_categorical_crossentropy/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_1 action_count 5697193716543326199 step 17118782394153560157 next 74\n",
      "2021-11-18 15:36:40.372354: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55ec300 of size 256 by op CudnnRNN/input_c action_count 5697193716543326203 step 0 next 78\n",
      "2021-11-18 15:36:40.372367: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55ec400 of size 40960 by op transpose_3 action_count 5697193716543326215 step 17295344833793694645 next 79\n",
      "2021-11-18 15:36:40.372379: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c55f6400 of size 61184 by op transpose_2 action_count 5697193716543326213 step 17295344833793694645 next 75\n",
      "2021-11-18 15:36:40.372391: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5605300 of size 512000 by op SameWorkerRecvDone action_count 5697193716543326196 step 0 next 76\n",
      "2021-11-18 15:36:40.372404: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5682300 of size 262144 by op ExpandDims action_count 5697193716543326202 step 0 next 77\n",
      "2021-11-18 15:36:40.372416: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c56c2300 of size 4235264 by op transpose_6 action_count 5697193716543326221 step 17295344833793694645 next 81\n",
      "2021-11-18 15:36:40.372429: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5acc300 of size 4194304 by op transpose_5 action_count 5697193716543326219 step 17295344833793694645 next 82\n",
      "2021-11-18 15:36:40.372441: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5ecc300 of size 4096 by op split_2 action_count 5697193716543326223 step 17295344833793694645 next 80\n",
      "2021-11-18 15:36:40.372458: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5ecd300 of size 4096 by op split_2 action_count 5697193716543326224 step 17295344833793694645 next 86\n",
      "2021-11-18 15:36:40.372470: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5ece300 of size 4096 by op split_2 action_count 5697193716543326225 step 17295344833793694645 next 87\n",
      "2021-11-18 15:36:40.372482: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5ecf300 of size 4096 by op split_2 action_count 5697193716543326226 step 17295344833793694645 next 88\n",
      "2021-11-18 15:36:40.372494: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5ed0300 of size 4096 by op split_2 action_count 5697193716543326227 step 17295344833793694645 next 89\n",
      "2021-11-18 15:36:40.372505: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c5ed1300 of size 4096 by op split_2 action_count 5697193716543326228 step 17295344833793694645 next 90\n",
      "2021-11-18 15:36:40.372517: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Free  at 7f03c5ed2300 of size 4169728 by op UNUSED action_count 0 step 0 next 83\n",
      "2021-11-18 15:36:40.372530: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c62cc300 of size 512000 by op transpose_0 action_count 5697193716543326210 step 17295344833793694645 next 84\n",
      "2021-11-18 15:36:40.372542: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c6349300 of size 40960 by op transpose_1 action_count 5697193716543326211 step 17295344833793694645 next 85\n",
      "2021-11-18 15:36:40.372554: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at 7f03c6353300 of size 5793536 by op transpose_4 action_count 5697193716543326217 step 17295344833793694645 next 18446744073709551615\n",
      "2021-11-18 15:36:40.372565: I tensorflow/core/common_runtime/bfc_allocator.cc:1051]      Summary of in-use Chunks by size: \n",
      "2021-11-18 15:36:40.372587: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 46 Chunks of size 256 totalling 11.5KiB\n",
      "2021-11-18 15:36:40.372603: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2021-11-18 15:36:40.372616: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 6 Chunks of size 4096 totalling 24.0KiB\n",
      "2021-11-18 15:36:40.372631: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 5 Chunks of size 24576 totalling 120.0KiB\n",
      "2021-11-18 15:36:40.372644: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 2 Chunks of size 40960 totalling 80.0KiB\n",
      "2021-11-18 15:36:40.372658: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 41984 totalling 41.0KiB\n",
      "2021-11-18 15:36:40.372671: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 2 Chunks of size 51200 totalling 100.0KiB\n",
      "2021-11-18 15:36:40.372685: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 61184 totalling 59.8KiB\n",
      "2021-11-18 15:36:40.372698: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 102400 totalling 100.0KiB\n",
      "2021-11-18 15:36:40.372712: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 3 Chunks of size 122880 totalling 360.0KiB\n",
      "2021-11-18 15:36:40.372726: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 123136 totalling 120.2KiB\n",
      "2021-11-18 15:36:40.372739: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 154624 totalling 151.0KiB\n",
      "2021-11-18 15:36:40.372753: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 5 Chunks of size 155648 totalling 760.0KiB\n",
      "2021-11-18 15:36:40.372767: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 192512 totalling 188.0KiB\n",
      "2021-11-18 15:36:40.372780: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 221184 totalling 216.0KiB\n",
      "2021-11-18 15:36:40.372794: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 2 Chunks of size 262144 totalling 512.0KiB\n",
      "2021-11-18 15:36:40.372811: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 2 Chunks of size 512000 totalling 1000.0KiB\n",
      "2021-11-18 15:36:40.372824: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 4194304 totalling 4.00MiB\n",
      "2021-11-18 15:36:40.372837: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 4235264 totalling 4.04MiB\n",
      "2021-11-18 15:36:40.372850: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 5793536 totalling 5.52MiB\n",
      "2021-11-18 15:36:40.372864: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 5 Chunks of size 12582912 totalling 60.00MiB\n",
      "2021-11-18 15:36:40.372877: I tensorflow/core/common_runtime/bfc_allocator.cc:1054] 1 Chunks of size 24698880 totalling 23.55MiB\n",
      "2021-11-18 15:36:40.372891: I tensorflow/core/common_runtime/bfc_allocator.cc:1058] Sum Total of in-use chunks: 100.87MiB\n",
      "2021-11-18 15:36:40.372904: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] total_region_allocated_bytes_: 109943296 memory_limit_: 122159104 available bytes: 12215808 curr_region_allocation_bytes_: 244318208\n",
      "2021-11-18 15:36:40.372923: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Stats: \n",
      "Limit:                       122159104\n",
      "InUse:                       105773568\n",
      "MaxInUse:                    109943296\n",
      "NumAllocs:                         176\n",
      "MaxAllocSize:                 24698880\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2021-11-18 15:36:40.372952: W tensorflow/core/common_runtime/bfc_allocator.cc:467] ************************xxxxxxxxxx*********************************************************___*****x\n",
      "2021-11-18 15:36:40.373015: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at concat_op.cc:158 : Resource exhausted: OOM when allocating tensor with shape[3182592] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d489e102",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign to variable embedding_1/embeddings:0 due to variable shape (38, 10) and value shape (38, 256) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57914/3488937265.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model.save_weights('pesos/embedings.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pesos/embedings.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2324\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2325\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    711\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    712\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m   \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3802\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m           \u001b[0mtensor_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    899\u001b[0m             (\"Cannot assign to variable%s due to variable shape %s and value \"\n\u001b[1;32m    900\u001b[0m              \"shape %s are incompatible\") %\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign to variable embedding_1/embeddings:0 due to variable shape (38, 10) and value shape (38, 256) are incompatible"
     ]
    }
   ],
   "source": [
    "#model.save_weights('pesos/embedings.hdf5')\n",
    "#model.load_weights('pesos/embedings.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e51fd",
   "metadata": {},
   "source": [
    "# Generando texto! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a66faa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57914/496229985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mOneStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars_from_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_from_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=0.6):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states\n",
    "\n",
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2e6392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amor  la tierra que hace poco \n",
      "si no te metas te muero\n",
      "y soy grande me ausente\n",
      "de nuevo volvere\n",
      "\n",
      "sembrando estrellas vivir\n",
      "\n",
      "perdon por ti cantan alli \n",
      "los teje mas de una vez\n",
      "\n",
      "a la huella  a la huella\n",
      "solito  senior \n",
      "con esta zamba que en cada esquina del portezuelo\n",
      "\n",
      "cuando se agranda la noche\n",
      "en la primavera \n",
      "florecen los santiaguenios\n",
      "donde estara la estrella que mate\n",
      "el se le curan las primaveras\n",
      "\n",
      "salgan mis saben si te van a decir\n",
      "que el hombre que te estoy muy serio\n",
      "y te amare que estoy viejo de \n",
      "\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['amor '])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(500):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611888c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

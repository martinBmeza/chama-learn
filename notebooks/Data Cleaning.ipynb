{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88316e8",
   "metadata": {},
   "source": [
    "POR HACER\n",
    "- Eliminar si contiene muy pocas lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2aaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7346da48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un total de 2522 canciones para procesar\n"
     ]
    }
   ],
   "source": [
    "txts_path = '../data/folclore-web/txts/'\n",
    "txts = glob.glob(txts_path+'**/*.txt', recursive=True)\n",
    "print('Hay un total de {} canciones para procesar'.format(len(txts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968844c8",
   "metadata": {},
   "source": [
    "Primero limpio cada letra de una, poniendo todo en minusculas y elminando los caracteres que no necesito. Despues voy a ver cuales agrego al dataset final y cuales no, para evitar por ejemplo repetir canciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f461bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_badline(text, flags):\n",
    "    text = text.split('\\n')\n",
    "    text_clean = []\n",
    "    for line in text:\n",
    "        if not any(flag in line for flag in flags):\n",
    "            text_clean.append(line)\n",
    "\n",
    "    return '\\n'.join(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7202b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arranco con una para ver que onda \n",
    "txt_path = txts[710]\n",
    "text = open(txt_path, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "text = text.lower() #todo a minuscula\n",
    "\n",
    "#saco los acentos\n",
    "no_van = ['á', 'é', 'í', 'ó', 'ú', 'ñ', '¡','!', '´', 'bis', ':', \"'\", '\"', '.', '-', '~', '`', '/','_',';','\\t','?','|','*']\n",
    "si_van = ['a', 'e', 'i', 'o', 'u','ni', '', ' ', '', '', '', '', '', '', '', 'ni','','','','','','','','']\n",
    "for sacar, poner in zip(no_van, si_van):\n",
    "    text = text.replace(sacar, poner)\n",
    "\n",
    "text = text.encode('ascii', 'ignore').decode()\n",
    "text = remove_badline(text, ['estribillo', 'Estribillo', 'xxx', '(', ')', '[', ']'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a152fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo soy,\n",
      "yo soy como el cerro negro,\n",
      "quebradenia\n",
      "y vos agita que me refresca\n",
      "mi jujenia\n",
      "\n",
      "yo soy\n",
      "sendita del cuesta arriba\n",
      "quebradenia\n",
      "y vos\n",
      "vientito que me acaricia,\n",
      "mi jujenia\n",
      "\n",
      "humpa le saben llamar\n",
      "a la cholita que penando esta\n",
      "humpa,\n",
      "asi te encontre en mi senda,\n",
      "mi jujenia\n",
      "\n",
      "me voy,\n",
      "me voy a las cumbres altas\n",
      "quebradenia\n",
      "donde,\n",
      "donde brillan las nevadas,\n",
      "mi jujenia\n",
      "\n",
      "alla,\n",
      "alla he de vivir pensando,\n",
      "quebradenia\n",
      "en el,\n",
      "en el sol de la quebrada,\n",
      "mi jujenia\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ebf3cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/folclore-web/clean_txts/'+txt_path.split('/')[-1], \"w\") as text_file:\n",
    "    text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f70cb5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 2522/2522 [00:00<00:00, 12684.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def data_cleaning(txt_path):\n",
    "    text = open(txt_path, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "    text = text.lower() #todo a minuscula\n",
    "\n",
    "    #saco los acentos\n",
    "    no_van = ['á', 'é', 'í', 'ó', 'ú', 'ñ', '¡','!', '´', 'bis', ':', \"'\", '\"', '.', '-', '~', '`', '/','_',';','\\t','?','|','*', ',']\n",
    "    si_van = ['a', 'e', 'i', 'o', 'u','ni', '', ' ', '', '', '', '', '', '', '', 'ni','','','','','','','','', ' ']\n",
    "    for sacar, poner in zip(no_van, si_van):\n",
    "        text = text.replace(sacar, poner)\n",
    "\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    text = remove_badline(text, ['estribillo', 'Estribillo', 'xxx', '(', ')', '[', ']'])\n",
    "    with open('../data/folclore-web/clean_txts/'+txt_path.split('/')[-1], \"w\") as text_file:\n",
    "        text_file.write(text)\n",
    "\n",
    "for txt_path in tqdm(txts):\n",
    "    data_cleaning(txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a666a5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a4dc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3aa264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02918e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un total de 66 canciones para procesar\n"
     ]
    }
   ],
   "source": [
    "txts_path = '../data/chamame-web/txts/'\n",
    "txts = glob.glob(txts_path+'**/*.txt', recursive=True)\n",
    "print('Hay un total de {} canciones para procesar'.format(len(txts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b9a816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 7100.24it/s]\n"
     ]
    }
   ],
   "source": [
    "def data_cleaning(txt_path):\n",
    "    text = open(txt_path, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "    text = text.lower() #todo a minuscula\n",
    "\n",
    "    #saco los acentos\n",
    "    no_van = ['á', 'é', 'í', 'ó', 'ú', 'ñ', '¡','!', '´', 'bis', ':', \"'\", '\"', '.', '-', '~', '`', '/','_',';','\\t','?','|','*', ',', '\\x0c']\n",
    "    si_van = ['a', 'e', 'i', 'o', 'u','ni', '', ' ', '', '', '', '', '', '', '', 'ni','','','','','','','','', ' ','']\n",
    "    for sacar, poner in zip(no_van, si_van):\n",
    "        text = text.replace(sacar, poner)\n",
    "\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    text = remove_badline(text, ['estribillo', 'Estribillo', 'xxx', '(', ')', '[', ']'])\n",
    "    with open('../data/chamame-web/clean_txts/'+txt_path.split('/')[-1], \"w\") as text_file:\n",
    "        text_file.write(text)\n",
    "\n",
    "for txt_path in tqdm(txts):\n",
    "    data_cleaning(txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7cc04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3def727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 10:43:24.918502: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Embedding, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c3fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['muy mala', 'mala comida', 'no volveria', 'no atienden bien', 'pesima atencion',\n",
    "          'muy buena', 'comida muy rica', 'lo recomiendo', 'buena atencion', 'lindo lugar']\n",
    "\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ce1820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded reviews: [[6, 43], [43, 24], [19, 35], [19, 15, 31], [8, 41], [6, 3], [24, 6, 41], [35, 26], [3, 41], [28, 12]]\n"
     ]
    }
   ],
   "source": [
    "Vocab_size = 50\n",
    "encoded_reviews = [one_hot(d, Vocab_size) for d in reviews] #convertir cada palabra en su indice one_hot\n",
    "print(f'encoded reviews: {encoded_reviews}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb40b2",
   "metadata": {},
   "source": [
    "El largo de cada review codificada es igual a la cantidad de palabras que contiene.\n",
    "Luego se aplica un padeo para que todas las reviews tengan la misma cantidad de palabras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3511784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 43  0  0]\n",
      " [43 24  0  0]\n",
      " [19 35  0  0]\n",
      " [19 15 31  0]\n",
      " [ 8 41  0  0]\n",
      " [ 6  3  0  0]\n",
      " [24  6 41  0]\n",
      " [35 26  0  0]\n",
      " [ 3 41  0  0]\n",
      " [28 12  0  0]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 4 \n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "print(padded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744fff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=Vocab_size, output_dim=8, input_length=max_length),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3dbc2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 11:29:03.981115: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-18 11:29:03.998337: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3199980000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 11:29:04.293782: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 873ms/step - loss: 0.6900 - acc: 0.6000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6887 - acc: 0.7000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6875 - acc: 0.7000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6863 - acc: 0.8000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6851 - acc: 0.8000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6839 - acc: 0.8000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6827 - acc: 0.8000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6815 - acc: 0.8000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6803 - acc: 0.8000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6791 - acc: 0.8000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.8000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6767 - acc: 0.8000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6755 - acc: 0.9000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6743 - acc: 0.9000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6731 - acc: 0.9000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6719 - acc: 0.9000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6706 - acc: 0.9000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6694 - acc: 0.9000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6682 - acc: 0.9000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6669 - acc: 0.9000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6657 - acc: 0.9000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6644 - acc: 0.9000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6631 - acc: 0.9000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6619 - acc: 0.9000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6606 - acc: 0.9000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6593 - acc: 0.9000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6580 - acc: 0.9000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6566 - acc: 0.9000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6553 - acc: 0.9000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6539 - acc: 0.9000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6526 - acc: 0.9000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6512 - acc: 0.9000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6498 - acc: 0.9000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6484 - acc: 0.9000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6470 - acc: 0.9000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.9000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6442 - acc: 0.9000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6428 - acc: 0.9000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6413 - acc: 0.9000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6398 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6383 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6368 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6353 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6338 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6323 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6307 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6292 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6276 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6260 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6244 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6228 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6211 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6195 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6178 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6162 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6145 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 11:29:04.868132: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6128 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6111 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6093 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6076 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6058 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6041 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6023 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6005 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5987 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5969 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5950 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5932 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5913 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5895 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5876 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5857 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5838 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5819 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5800 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5780 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5761 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5742 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5722 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5702 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5682 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5662 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5642 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5622 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5602 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5582 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5561 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5541 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5520 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5500 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5479 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5458 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5437 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5416 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5395 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5374 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5353 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5332 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5311 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5290 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f537f8d9400>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_reviews, labels, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce17d9b",
   "metadata": {},
   "source": [
    "Analizo la capa de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195c1e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ce7e3",
   "metadata": {},
   "source": [
    "De esta forma se construye esta look-up table en donde se definen representaciones vectoriales complejas de cada palabra, para luego usar esas representaciones en el entrenamiento de modelos. \n",
    "El embedding entonces es util para reducir y controlar la dimensionalidad de la entrada. Además, sirve también para el entrenamiento, ya que palabras similares tendran vectores similares (si medimos la distancia entre los vectores de cada palabra) por lo que se dice que logra comprender el contexto de las palabras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5397b1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03654153,  0.00487402,  0.02915067,  0.01064066, -0.02204375,\n",
       "         0.00550731,  0.01894402, -0.008373  ],\n",
       "       [ 0.01398249,  0.04996587,  0.03504917, -0.04931144, -0.00684848,\n",
       "        -0.01316261,  0.0144709 ,  0.01086054],\n",
       "       [ 0.01340405,  0.02136347, -0.04304823,  0.00463307, -0.03633474,\n",
       "        -0.01735854,  0.00670094, -0.04261947],\n",
       "       [ 0.06213295,  0.13782373,  0.1406892 , -0.12761796,  0.06027074,\n",
       "         0.16188532,  0.10159532,  0.06858815],\n",
       "       [ 0.03233233, -0.01768253,  0.03233585, -0.03782239, -0.01496118,\n",
       "         0.03388165,  0.00948422,  0.01655096],\n",
       "       [ 0.03591115, -0.03086826,  0.02316078,  0.01327726,  0.00955842,\n",
       "         0.02788012, -0.00577217,  0.04274372],\n",
       "       [ 0.13293459, -0.11894173,  0.1089919 ,  0.0626514 ,  0.13174963,\n",
       "         0.08455895, -0.13400292,  0.14563218],\n",
       "       [-0.04397264,  0.04545008, -0.00553574, -0.0047638 , -0.0315155 ,\n",
       "        -0.03816116,  0.0435478 , -0.03272069],\n",
       "       [ 0.15327074, -0.15201841, -0.12637064,  0.1580636 , -0.09348089,\n",
       "        -0.10866235, -0.1349736 ,  0.14155439],\n",
       "       [-0.00232582,  0.00740623,  0.03505392, -0.00474663,  0.04593554,\n",
       "         0.00289597,  0.01257029, -0.00968213],\n",
       "       [ 0.03122956,  0.02333182,  0.04427345,  0.03518868, -0.04668027,\n",
       "        -0.00104184,  0.03886307, -0.02516735],\n",
       "       [ 0.03804714, -0.0266663 ,  0.00406457, -0.02956787, -0.04564191,\n",
       "         0.03281305,  0.04882431, -0.04308734],\n",
       "       [ 0.14796065, -0.14747517,  0.14555508,  0.10563512,  0.13398935,\n",
       "         0.14280413, -0.06785484,  0.11896966],\n",
       "       [ 0.03853072,  0.00431991, -0.01270054,  0.01725257,  0.04063852,\n",
       "         0.02430124, -0.0452834 , -0.03492358],\n",
       "       [-0.02322527,  0.0313658 , -0.00455093, -0.00279947, -0.03082295,\n",
       "        -0.04926517,  0.0346701 , -0.01971797],\n",
       "       [-0.09366795,  0.08583452, -0.13996844, -0.09353387, -0.13360909,\n",
       "        -0.13818139,  0.11682729, -0.06679117],\n",
       "       [ 0.02692877,  0.02109009, -0.01552318, -0.0282945 ,  0.03496821,\n",
       "         0.02347852, -0.02330116,  0.04198258],\n",
       "       [ 0.00679912,  0.01306113, -0.03836796,  0.00287684,  0.03452135,\n",
       "        -0.01563077,  0.0291549 , -0.04839672],\n",
       "       [-0.02889848,  0.01467491,  0.02509311, -0.01719936,  0.00512239,\n",
       "         0.01187832, -0.01963907, -0.03271727],\n",
       "       [ 0.08142705, -0.12230989, -0.0704582 ,  0.123753  , -0.05384992,\n",
       "        -0.13006188, -0.1011315 ,  0.08406081],\n",
       "       [-0.00727363,  0.04767538,  0.01171682, -0.02344401, -0.01086278,\n",
       "         0.01141723, -0.01094346,  0.01913123],\n",
       "       [-0.04133991, -0.02459176, -0.04304842,  0.00746306, -0.04458236,\n",
       "         0.04134324,  0.04073704,  0.02848775],\n",
       "       [ 0.00459873,  0.00021311, -0.01940885,  0.01628229, -0.02017774,\n",
       "        -0.01298524,  0.01896726, -0.02427676],\n",
       "       [ 0.02138874, -0.02427883,  0.0458264 ,  0.02222672, -0.01412959,\n",
       "         0.03639582, -0.02490951, -0.02385833],\n",
       "       [-0.12946033,  0.11622751, -0.07558663, -0.06671338, -0.15656774,\n",
       "         0.08523663,  0.08458054, -0.07242481],\n",
       "       [-0.04466809, -0.0160136 , -0.00354755, -0.0421619 , -0.00429219,\n",
       "         0.02797642, -0.00518751,  0.00076076],\n",
       "       [ 0.13953663, -0.09102496,  0.10346156,  0.13257647,  0.07992951,\n",
       "         0.11548322, -0.13340797,  0.13988008],\n",
       "       [-0.00640572,  0.03762641, -0.04676877, -0.04935017, -0.01975476,\n",
       "         0.00761805,  0.01655939, -0.04831246],\n",
       "       [-0.08504294,  0.07713506,  0.12001114, -0.06628186,  0.11695644,\n",
       "         0.08948682,  0.06507807, -0.08873427],\n",
       "       [ 0.02591798,  0.03364163, -0.00055636,  0.03670343, -0.01599038,\n",
       "        -0.04793881,  0.00016611, -0.01694107],\n",
       "       [ 0.04670448,  0.0389096 ,  0.00572964,  0.02756907, -0.03595946,\n",
       "         0.04629285,  0.04148301, -0.02060735],\n",
       "       [ 0.11909687,  0.06944875, -0.06272198,  0.11238242,  0.12702723,\n",
       "        -0.1486688 ,  0.12886094, -0.04961964],\n",
       "       [-0.03467374,  0.00309882,  0.03528215,  0.0306779 ,  0.01330907,\n",
       "        -0.04842619, -0.00404485,  0.03971985],\n",
       "       [ 0.02347387, -0.03479834, -0.01755533,  0.00442196, -0.04675778,\n",
       "        -0.02669322, -0.04698059, -0.02557485],\n",
       "       [-0.00377133, -0.00596749,  0.04255321, -0.00257455, -0.04702787,\n",
       "        -0.02949529,  0.01284427, -0.02700462],\n",
       "       [-0.15392594,  0.14752865, -0.06748313, -0.14105636, -0.14930609,\n",
       "         0.11706637,  0.10945319, -0.05289487],\n",
       "       [ 0.04737114,  0.00382776, -0.04457502,  0.01494521,  0.03907743,\n",
       "         0.01485808,  0.03943578,  0.02878064],\n",
       "       [ 0.04411625, -0.02239536,  0.00420797,  0.00982459,  0.0401736 ,\n",
       "         0.01041977,  0.00752932,  0.01655352],\n",
       "       [-0.03413014, -0.014484  , -0.03135352,  0.04773858, -0.02805558,\n",
       "        -0.00444579,  0.02897365,  0.02742303],\n",
       "       [ 0.02814765, -0.02683013, -0.03668907,  0.02803445,  0.01312938,\n",
       "         0.04862135,  0.02293838,  0.00362706],\n",
       "       [-0.00793438,  0.0219767 , -0.04689839, -0.04971233, -0.01441969,\n",
       "         0.02848632,  0.04456451,  0.01447472],\n",
       "       [-0.14096436, -0.10777512,  0.08747564, -0.06248702, -0.13501957,\n",
       "         0.15054442, -0.05514431,  0.07740763],\n",
       "       [ 0.04388067, -0.03689774, -0.03971788, -0.01554897,  0.04250573,\n",
       "         0.02081669,  0.02660947,  0.02935928],\n",
       "       [-0.13255645, -0.08630133, -0.12445503,  0.06975798, -0.10233174,\n",
       "        -0.14937648, -0.1307071 , -0.08302839],\n",
       "       [ 0.00776595,  0.03888024,  0.01309646,  0.049379  ,  0.01990125,\n",
       "        -0.00134217, -0.03583596, -0.0451325 ],\n",
       "       [-0.01102151,  0.01777654,  0.04113782,  0.03766486, -0.00959941,\n",
       "         0.04589852, -0.04664897,  0.02023388],\n",
       "       [-0.0273295 , -0.02205397,  0.00468038,  0.02996707, -0.02298744,\n",
       "         0.02209005, -0.01631258, -0.04622594],\n",
       "       [ 0.0321554 ,  0.01518347,  0.00836398,  0.01127934,  0.00456476,\n",
       "         0.0369021 ,  0.01144149,  0.02369417],\n",
       "       [-0.00915557,  0.0140723 ,  0.04407264,  0.00472927, -0.01832717,\n",
       "        -0.00534561, -0.03683583, -0.01782616],\n",
       "       [ 0.01785455,  0.04300288, -0.01009094,  0.04118   ,  0.01995845,\n",
       "         0.03302375,  0.03731402,  0.02300974]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d145d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
